{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit CoFactor model to the binarized ML20M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "sns.set(context=\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2}, font='DejaVu Serif')\n",
    "import sys\n",
    "sys.path.append('E:\\workspace\\source_code\\cofactor\\src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cofacto\n",
    "import rec_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the positive pairwise mutual information (PPMI) matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this to wherever you saved the pre-processed data following [this notebook](./preprocess_ML20M.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'E:\\datasets\\ml-20m\\pro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_uid = list()\n",
    "with open(os.path.join(DATA_DIR, 'unique_uid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "    \n",
    "unique_sid = list()\n",
    "with open(os.path.join(DATA_DIR, 'unique_sid.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111148 11711\n"
     ]
    }
   ],
   "source": [
    "n_items = len(unique_sid)\n",
    "n_users = len(unique_uid)\n",
    "\n",
    "print n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(csv_file, shape=(n_users, n_items)):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    timestamps, rows, cols = np.array(tp['timestamp']), np.array(tp['uid']), np.array(tp['sid'])\n",
    "    seq = np.concatenate((rows[:, None], cols[:, None], np.ones((rows.size, 1), dtype='int'), timestamps[:, None]), axis=1)\n",
    "    data = sparse.csr_matrix((np.ones_like(rows), (rows, cols)), dtype=np.int16, shape=shape)\n",
    "    return data, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_raw = load_data(os.path.join(DATA_DIR, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watches_per_movie = np.asarray(train_data.astype('int64').sum(axis=0)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean (median) watches per movie is 597 (48)\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean (median) watches per movie is %d (%d)\" % (watches_per_movie.mean(), np.median(watches_per_movie)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_activity = np.asarray(train_data.sum(axis=1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean (median) movies each user wathced is 62 (33)\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean (median) movies each user wathced is %d (%d)\" % (user_activity.mean(), np.median(user_activity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vad_data, vad_raw = load_data(os.path.join(DATA_DIR, 'validation.csv')) #返回的是一个稀疏矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogx(1 + np.arange(n_users), -np.sort(-user_activity), 'o')\n",
    "plt.ylabel('Number of items that this user clicked on')\n",
    "plt.xlabel('User rank by number of consumed items')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogx(1 + np.arange(n_items), -np.sort(-watches_per_movie), 'o')\n",
    "plt.ylabel('Number of users who watched this movie')\n",
    "plt.xlabel('Movie rank by number of watches')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate co-occurrence matrix based on the user's entire watching history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _coord_batch(lo, hi, train_data):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for u in xrange(lo, hi):\n",
    "        for w, c in itertools.permutations(train_data[u].nonzero()[1], 2):\n",
    "            rows.append(w)\n",
    "            cols.append(c)\n",
    "    np.save(os.path.join(DATA_DIR, 'coo_%d_%d.npy' % (lo, hi)),\n",
    "            np.concatenate([np.array(rows)[:, None], np.array(cols)[:, None]], axis=1))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "sns.set(context=\"paper\", font_scale=1.5, rc={\"lines.linewidth\": 2}, font='DejaVu Serif')\n",
    "def _coord_batch(lo, hi, train_data):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for u in xrange(lo, hi):\n",
    "        for w, c in itertools.permutations(train_data[u].nonzero()[1], 2):\n",
    "            rows.append(w)\n",
    "            cols.append(c)\n",
    "    np.save(os.path.join(DATA_DIR, 'coo_%d_%d.npy' % (lo, hi)),\n",
    "            np.concatenate([np.array(rows)[:, None], np.array(cols)[:, None]], axis=1))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "batch_size = 5000\n",
    "\n",
    "start_idx = range(0, n_users, batch_size)\n",
    "end_idx = start_idx[1:] + [n_users]\n",
    "\n",
    "'''Parallel(n_jobs=8)(delayed(_coord_batch)(lo, hi, train_data) for lo, hi in zip(start_idx, end_idx))\n",
    "\n",
    "'''\n",
    "for lo, hi in zip(start_idx, end_idx):\n",
    "\t\t_coord_batch(lo, hi, train_data)\n",
    "\n",
    "\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 to 5000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 5000 to 10000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 10000 to 15000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 15000 to 20000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 20000 to 25000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 25000 to 30000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 30000 to 35000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 35000 to 40000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 40000 to 45000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 45000 to 50000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 50000 to 55000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 55000 to 60000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 60000 to 65000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 65000 to 70000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 70000 to 75000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 75000 to 80000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 80000 to 85000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 85000 to 90000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 90000 to 95000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 95000 to 100000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 100000 to 105000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 105000 to 110000 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 110000 to 111148 finished\n"
     ]
    }
   ],
   "source": [
    "X = sparse.csr_matrix((n_items, n_items), dtype='float32')\n",
    "for lo, hi in zip(start_idx, end_idx):\n",
    "    coords = np.load(os.path.join(DATA_DIR, 'coo_%d_%d.npy' % (lo, hi)))\n",
    "    \n",
    "    rows = coords[:, 0]\n",
    "    cols = coords[:, 1]\n",
    "    \n",
    "    tmp = sparse.coo_matrix((np.ones_like(rows), (rows, cols)), shape=(n_items, n_items), dtype='float32').tocsr()\n",
    "    X = X + tmp\n",
    "    \n",
    "    print(\"User %d to %d finished\" % (lo, hi))\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Don't forget to delete all the temporary coo_LO_HI.npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(DATA_DIR, 'coordinate_co_binary_data.npy'), X.data)\n",
    "np.save(os.path.join(DATA_DIR, 'coordinate_co_binary_indices.npy'), X.indices)\n",
    "np.save(os.path.join(DATA_DIR, 'coordinate_co_binary_indptr.npy'), X.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38557504805354814"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(X.nnz) / np.prod(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load the pre-saved co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or co-occurrence matrix from the entire user history\n",
    "dir_predix = DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(dir_predix, 'coordinate_co_binary_data.npy'))\n",
    "indices = np.load(os.path.join(dir_predix, 'coordinate_co_binary_indices.npy'))\n",
    "indptr = np.load(os.path.join(dir_predix, 'coordinate_co_binary_indptr.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sparse.csr_matrix((data, indices, indptr), shape=(n_items, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38557504805354814"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(X.nnz) / np.prod(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_row(Y, i):\n",
    "    lo, hi = Y.indptr[i], Y.indptr[i + 1]\n",
    "    return lo, hi, Y.data[lo:hi], Y.indices[lo:hi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = np.asarray(X.sum(axis=1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pairs = X.data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the SPPMI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = X.copy()\n",
    "\n",
    "for i in xrange(n_items):\n",
    "    lo, hi, d, idx = get_row(M, i)\n",
    "    M.data[lo:hi] = np.log(d * n_pairs / (count[i] * count[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.data[M.data < 0] = 0\n",
    "M.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.237642385093\n"
     ]
    }
   ],
   "source": [
    "print float(M.nnz) / np.prod(M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now $M$ is the PPMI matrix. Depending on the number of negative examples $k$, we can obtain the shifted PPMI matrix as $\\max(M_{wc} - \\log k, 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of negative samples\n",
    "k_ns = 1\n",
    "\n",
    "M_ns = M.copy()\n",
    "\n",
    "if k_ns > 1:\n",
    "    offset = np.log(k_ns)\n",
    "else:\n",
    "    offset = 0.\n",
    "    \n",
    "M_ns.data -= offset\n",
    "M_ns.data[M_ns.data < 0] = 0\n",
    "M_ns.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(M_ns.data, bins=50)\n",
    "plt.yscale('log')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23764238509276445"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(M_ns.nnz) / np.prod(M_ns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = 0.03\n",
    "\n",
    "n_components = 100\n",
    "max_iter = 20\n",
    "n_jobs = 8\n",
    "lam_theta = lam_beta = 1e-5 * scale\n",
    "lam_gamma = 1e-5\n",
    "c0 = 1. * scale\n",
    "c1 = 10. * scale\n",
    "\n",
    "save_dir = os.path.join(DATA_DIR, 'ML20M_ns%d_scale%1.2E' % (k_ns, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(cofacto)\n",
    "coder = cofacto.CoFacto(n_components=n_components, max_iter=max_iter, batch_size=1000, init_std=0.01, n_jobs=n_jobs, \n",
    "                        random_state=98765, save_params=True, save_dir=save_dir, early_stopping=True, verbose=True, \n",
    "                        lam_theta=lam_theta, lam_beta=lam_beta, lam_gamma=lam_gamma, c0=c0, c1=c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=17.18\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=21.16\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.31\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=28.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\workspace\\GitHub_file\\cofactor-master\\src\\rec_eval.py:267: RuntimeWarning: invalid value encountered in divide\n  return DCG / IDCG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.19163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #1\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=14.96\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=21.41\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.22\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=29.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.26963\nITERATION #2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=14.79\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=21.00\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.17\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=28.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.34485\nITERATION #3\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=14.77\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=20.81\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.18\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=28.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.35849\nITERATION #4\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=14.94\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=21.22\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.07\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=28.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.36298\nITERATION #5\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=14.88\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=21.77\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=16.67\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=31.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.36325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #6\n\tUpdating user factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating user factors: time=16.81\n\tUpdating item factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating item factors: time=24.21\n\tUpdating context factors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating context factors: time=17.03\n\tUpdating bias terms..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\tUpdating bias terms: time=29.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidation NDCG@k: 0.36150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CoFacto(batch_size=1000, dtype='float32', early_stopping=True, init_std=0.01,\n    max_iter=20, n_components=100, n_jobs=8, random_state=98765,\n    save_dir='E:\\\\datasets\\\\ml-20m\\\\pro\\\\ML20M_ns1_scale3.00E-02',\n    save_params=True, verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coder.fit(train_data, M_ns, vad_data=vad_data, batch_users=5000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data, _ = load_data(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test_data.data = np.ones_like(test_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_params = len(glob.glob(os.path.join(save_dir, '*.npz')))\n",
    "\n",
    "params = np.load(os.path.join(save_dir, 'CoFacto_K%d_iter%d.npz' % (n_components, n_params - 1)))\n",
    "U, V = params['U'], params['V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\workspace\\GitHub_file\\cofactor-master\\src\\rec_eval.py:193: RuntimeWarning: invalid value encountered in divide\n  recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@20: 0.1448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall@50: 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100: 0.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAP@100: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print 'Test Recall@20: %.4f' % rec_eval.recall_at_k(train_data, test_data, U, V, k=20, vad_data=vad_data)\n",
    "print 'Test Recall@50: %.4f' % rec_eval.recall_at_k(train_data, test_data, U, V, k=50, vad_data=vad_data)\n",
    "print 'Test NDCG@100: %.4f' % rec_eval.normalized_dcg_at_k(train_data, test_data, U, V, k=100, vad_data=vad_data)\n",
    "print 'Test MAP@100: %.4f' % rec_eval.map_at_k(train_data, test_data, U, V, k=100, vad_data=vad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('CoFactor_K100_ML20M.npz', U=U, V=V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
